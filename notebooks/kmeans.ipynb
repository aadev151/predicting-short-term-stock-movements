{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# K-Means Clustering – Stock & Market-Day Segmentation\n",
    "\n",
    "Unsupervised analysis with two complementary views:\n",
    "\n",
    "### Part 1 – Stock Behavioral Clustering\n",
    "Aggregate each ticker's trading history into a summary profile (mean return, volatility, Sharpe proxy, volume behaviour, momentum, sentiment) and cluster tickers into behavioral archetypes.\n",
    "\n",
    "### Part 2 – Market Day Clustering\n",
    "Aggregate across tickers each day (cross-sectional mean return, dispersion, breadth, VIX, yield spread) and cluster days into market environment types.\n",
    "\n",
    "Cluster labels can later be used as additional features in the supervised models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 5)\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-load",
   "metadata": {},
   "source": [
    "## 1. Load Data & Derive Base Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/merged_dataset.csv', parse_dates=['date'])\n",
    "df = df.sort_values(['ticker', 'date']).reset_index(drop=True)\n",
    "print(f'Shape: {df.shape}')\n",
    "\n",
    "# ── Derived columns used by both parts ────────────────────────────────────────\n",
    "df['price_to_ma20'] = (\n",
    "    df['close'] / df['rolling_mean_20'].replace(0, np.nan)\n",
    ").replace([np.inf, -np.inf], np.nan) - 1\n",
    "\n",
    "df['hl_range'] = (df['high'] - df['low']) / df['close'].replace(0, np.nan)\n",
    "\n",
    "df['vol_20ma'] = df.groupby('ticker')['volume'].transform(\n",
    "    lambda x: x.rolling(20, min_periods=1).mean()\n",
    ")\n",
    "df['vol_norm'] = (df['volume'] / df['vol_20ma'].replace(0, np.nan)).clip(0, 10)\n",
    "\n",
    "# Impute sparse columns with neutral values\n",
    "df['VIX']            = df['VIX'].fillna(df['VIX'].median())\n",
    "df['Yield_Spread']   = df['Yield_Spread'].fillna(df['Yield_Spread'].median())\n",
    "df['sentiment_mean'] = df['sentiment_mean'].fillna(0)\n",
    "\n",
    "# Binary: was next-day return positive?\n",
    "df['up'] = (df.groupby('ticker')['daily_return'].shift(-1) > 0).astype(float)\n",
    "\n",
    "print('Base features derived.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-part1",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 – Stock Behavioral Clustering\n",
    "\n",
    "Summarise each ticker over its full history into a fixed-length feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-ticker-agg",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_stats = df.groupby('ticker').agg(\n",
    "    mean_return       = ('daily_return',   'mean'),\n",
    "    std_return        = ('daily_return',   'std'),\n",
    "    mean_hl_range     = ('hl_range',       'mean'),\n",
    "    mean_vol_norm     = ('vol_norm',       'mean'),\n",
    "    mean_price_to_ma  = ('price_to_ma20',  'mean'),\n",
    "    mean_sentiment    = ('sentiment_mean', 'mean'),\n",
    "    up_rate           = ('up',             'mean'),   # win rate\n",
    "    log_marketcap     = ('Marketcap',      lambda x: np.log1p(x.dropna().median())),\n",
    "    revenuegrowth     = ('Revenuegrowth',  'median'),\n",
    "    weight            = ('Weight',         'first'),\n",
    ").dropna()\n",
    "\n",
    "# Sharpe-like ratio\n",
    "ticker_stats['sharpe_approx'] = (\n",
    "    ticker_stats['mean_return'] / (ticker_stats['std_return'] + 1e-9)\n",
    ")\n",
    "\n",
    "# Also keep Sector for later interpretation\n",
    "sector_map = df.groupby('ticker')['Sector'].first()\n",
    "ticker_stats = ticker_stats.join(sector_map)\n",
    "\n",
    "print(f'Tickers in clustering set: {len(ticker_stats)}')\n",
    "ticker_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-elbow1",
   "metadata": {},
   "source": [
    "### Elbow Method & Silhouette Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-elbow1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER_FEAT_COLS = [\n",
    "    'mean_return', 'std_return', 'sharpe_approx',\n",
    "    'mean_hl_range', 'mean_vol_norm', 'mean_price_to_ma',\n",
    "    'mean_sentiment', 'up_rate',\n",
    "    'log_marketcap', 'revenuegrowth', 'weight',\n",
    "]\n",
    "\n",
    "X_tickers = ticker_stats[TICKER_FEAT_COLS].dropna()\n",
    "print(f'Tickers after dropna: {len(X_tickers)}')\n",
    "\n",
    "scaler_t = StandardScaler()\n",
    "X_tickers_s = scaler_t.fit_transform(X_tickers)\n",
    "\n",
    "inertias, sil_scores = [], []\n",
    "K_RANGE = range(2, 13)\n",
    "\n",
    "for k in K_RANGE:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "    labels = km.fit_predict(X_tickers_s)\n",
    "    inertias.append(km.inertia_)\n",
    "    if k <= 8:\n",
    "        sil_scores.append(silhouette_score(X_tickers_s, labels, sample_size=min(len(X_tickers_s), 2000)))\n",
    "    else:\n",
    "        sil_scores.append(None)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].plot(list(K_RANGE), inertias, marker='o')\n",
    "axes[0].set_title('Elbow Method – Stock Clustering')\n",
    "axes[0].set_xlabel('k')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "\n",
    "sil_vals = [s for s in sil_scores if s is not None]\n",
    "sil_ks   = [k for k, s in zip(K_RANGE, sil_scores) if s is not None]\n",
    "axes[1].plot(sil_ks, sil_vals, marker='o', color='orange')\n",
    "axes[1].set_title('Silhouette Score – Stock Clustering')\n",
    "axes[1].set_xlabel('k')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-km1-fit",
   "metadata": {},
   "source": [
    "### Fit K-Means & Visualise with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-km1-fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_STOCKS = 5  # adjust based on elbow / silhouette above\n",
    "\n",
    "km_stocks = KMeans(n_clusters=K_STOCKS, random_state=RANDOM_STATE, n_init=20)\n",
    "ticker_stats.loc[X_tickers.index, 'cluster'] = km_stocks.fit_predict(X_tickers_s)\n",
    "ticker_stats['cluster'] = ticker_stats['cluster'].astype('Int64')\n",
    "\n",
    "# PCA for 2-D visualisation\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "coords = pca.fit_transform(X_tickers_s)\n",
    "\n",
    "plot_df = X_tickers.copy()\n",
    "plot_df['pc1']     = coords[:, 0]\n",
    "plot_df['pc2']     = coords[:, 1]\n",
    "plot_df['cluster'] = km_stocks.labels_\n",
    "plot_df['ticker']  = X_tickers.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "palette = sns.color_palette('tab10', K_STOCKS)\n",
    "for c in range(K_STOCKS):\n",
    "    sub = plot_df[plot_df['cluster'] == c]\n",
    "    ax.scatter(sub['pc1'], sub['pc2'], label=f'Cluster {c}', alpha=0.7, s=40, color=palette[c])\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
    "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
    "ax.set_title(f'Stock Clusters in PCA Space  (k={K_STOCKS})')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Cluster sizes:\\n{plot_df[\"cluster\"].value_counts().sort_index()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-km1-profile",
   "metadata": {},
   "source": [
    "### Cluster Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-km1-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_cols = [\n",
    "    'mean_return', 'std_return', 'sharpe_approx',\n",
    "    'mean_hl_range', 'mean_vol_norm',\n",
    "    'mean_price_to_ma', 'up_rate',\n",
    "    'log_marketcap', 'revenuegrowth',\n",
    "]\n",
    "\n",
    "profiles = (\n",
    "    ticker_stats.dropna(subset=['cluster'])\n",
    "    .groupby('cluster')[profile_cols]\n",
    "    .mean()\n",
    "    .round(4)\n",
    ")\n",
    "print('=== Cluster Mean Profiles ===')\n",
    "print(profiles.to_string())\n",
    "\n",
    "# Heatmap (z-scored across clusters)\n",
    "profiles_z = (profiles - profiles.mean()) / (profiles.std() + 1e-9)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.heatmap(\n",
    "    profiles_z.T, annot=profiles.T.round(4),\n",
    "    fmt='g', cmap='RdBu_r', center=0,\n",
    "    ax=ax, cbar_kws={'label': 'z-score'},\n",
    ")\n",
    "ax.set_title('Stock Cluster Profiles (z-scored)')\n",
    "ax.set_xlabel('Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-sector-dist",
   "metadata": {},
   "source": [
    "### Sector Distribution per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-sector-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_cluster = (\n",
    "    ticker_stats.dropna(subset=['cluster'])\n",
    "    .groupby(['cluster', 'Sector'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "# Normalise to % within each cluster\n",
    "sector_pct = sector_cluster.div(sector_cluster.sum(axis=1), axis=0) * 100\n",
    "\n",
    "sector_pct.plot.bar(stacked=True, figsize=(12, 5), colormap='tab20')\n",
    "plt.title('Sector Composition per Stock Cluster (%)')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('% of cluster')\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-part2",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 – Market Day Clustering\n",
    "\n",
    "Aggregate across all tickers each day to capture the macro environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-day-agg",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_stats = df.groupby('date').agg(\n",
    "    mean_return    = ('daily_return', 'mean'),\n",
    "    std_return     = ('daily_return', 'std'),    # cross-sectional dispersion\n",
    "    breadth        = ('up',           'mean'),   # % tickers that went up\n",
    "    mean_hl_range  = ('hl_range',     'mean'),\n",
    "    mean_vol_norm  = ('vol_norm',     'mean'),\n",
    "    VIX            = ('VIX',          'first'),\n",
    "    Yield_Spread   = ('Yield_Spread', 'first'),\n",
    "    sp500          = ('S&P500',       'first'),\n",
    ").dropna()\n",
    "\n",
    "# Add S&P 500 daily return\n",
    "daily_stats['sp500_ret'] = daily_stats['sp500'].pct_change()\n",
    "daily_stats = daily_stats.dropna()\n",
    "\n",
    "print(f'Trading days: {len(daily_stats)}')\n",
    "daily_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-elbow2",
   "metadata": {},
   "source": [
    "### Elbow Method & Silhouette Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-elbow2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY_FEAT_COLS = [\n",
    "    'mean_return', 'std_return', 'breadth',\n",
    "    'mean_hl_range', 'mean_vol_norm',\n",
    "    'VIX', 'Yield_Spread', 'sp500_ret',\n",
    "]\n",
    "\n",
    "X_days = daily_stats[DAY_FEAT_COLS].dropna()\n",
    "scaler_d = StandardScaler()\n",
    "X_days_s = scaler_d.fit_transform(X_days)\n",
    "\n",
    "inertias_d, sil_d = [], []\n",
    "for k in range(2, 11):\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "    lbl = km.fit_predict(X_days_s)\n",
    "    inertias_d.append(km.inertia_)\n",
    "    sil_d.append(silhouette_score(X_days_s, lbl))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "axes[0].plot(range(2, 11), inertias_d, marker='o')\n",
    "axes[0].set_title('Elbow Method – Day Clustering')\n",
    "axes[0].set_xlabel('k')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "\n",
    "axes[1].plot(range(2, 11), sil_d, marker='o', color='orange')\n",
    "axes[1].set_title('Silhouette Score – Day Clustering')\n",
    "axes[1].set_xlabel('k')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-km2-fit",
   "metadata": {},
   "source": [
    "### Fit K-Means & Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-km2-fit",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_DAYS = 4  # adjust based on elbow / silhouette above\n",
    "\n",
    "km_days = KMeans(n_clusters=K_DAYS, random_state=RANDOM_STATE, n_init=20)\n",
    "daily_stats_sub = daily_stats.loc[X_days.index].copy()\n",
    "daily_stats_sub['cluster'] = km_days.fit_predict(X_days_s)\n",
    "\n",
    "# Sort clusters by mean return for consistent labelling\n",
    "cluster_order = (\n",
    "    daily_stats_sub.groupby('cluster')['mean_return']\n",
    "    .mean()\n",
    "    .sort_values()\n",
    "    .index.tolist()\n",
    ")\n",
    "remap = {old: new for new, old in enumerate(cluster_order)}\n",
    "daily_stats_sub['cluster'] = daily_stats_sub['cluster'].map(remap)\n",
    "\n",
    "cluster_names = {0: 'Bearish', 1: 'Weak', 2: 'Moderate', 3: 'Bullish'}\n",
    "daily_stats_sub['regime'] = daily_stats_sub['cluster'].map(cluster_names)\n",
    "\n",
    "palette = {'Bearish': 'salmon', 'Weak': 'gold', 'Moderate': 'skyblue', 'Bullish': 'seagreen'}\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True)\n",
    "\n",
    "# S&P 500 with regime shading\n",
    "sp500_ts = daily_stats_sub['sp500'].sort_index()\n",
    "axes[0].plot(sp500_ts.index, sp500_ts.values, lw=0.8, color='black')\n",
    "axes[0].set_ylabel('S&P 500')\n",
    "axes[0].set_title('S&P 500 with K-Means Market Day Regimes')\n",
    "for regime, color in palette.items():\n",
    "    mask = daily_stats_sub['regime'] == regime\n",
    "    for date in daily_stats_sub.loc[mask].index:\n",
    "        axes[0].axvspan(date, date + pd.Timedelta(days=1), alpha=0.15, color=color, lw=0)\n",
    "\n",
    "# VIX\n",
    "axes[1].plot(daily_stats_sub.index, daily_stats_sub['VIX'], lw=0.8, color='darkred')\n",
    "axes[1].set_ylabel('VIX')\n",
    "\n",
    "# Cluster label timeline\n",
    "for regime, color in palette.items():\n",
    "    sub = daily_stats_sub[daily_stats_sub['regime'] == regime]\n",
    "    axes[2].scatter(sub.index, [regime] * len(sub), c=color, s=8, label=regime)\n",
    "axes[2].set_ylabel('Regime')\n",
    "axes[2].legend(loc='upper left', markerscale=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-km2-profile",
   "metadata": {},
   "source": [
    "### Day Cluster Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-km2-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_profiles = (\n",
    "    daily_stats_sub.groupby('regime')[DAY_FEAT_COLS]\n",
    "    .mean()\n",
    "    .round(4)\n",
    "    .loc[['Bearish', 'Weak', 'Moderate', 'Bullish']]\n",
    ")\n",
    "print('=== Day Cluster Profiles ===')\n",
    "print(day_profiles.to_string())\n",
    "\n",
    "day_profiles_z = (day_profiles - day_profiles.mean()) / (day_profiles.std() + 1e-9)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.heatmap(\n",
    "    day_profiles_z.T,\n",
    "    annot=day_profiles.T.round(3),\n",
    "    fmt='g', cmap='RdBu_r', center=0,\n",
    "    ax=ax, cbar_kws={'label': 'z-score'},\n",
    "    xticklabels=day_profiles_z.index,\n",
    ")\n",
    "ax.set_title('Market Day Cluster Profiles (z-scored)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-compare-regime",
   "metadata": {},
   "source": [
    "### Compare K-Means Regimes to Existing GMM Regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c-compare-regime",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_daily = df.groupby('date')['Regime_label'].first().dropna()\n",
    "compare = daily_stats_sub[['regime']].join(gmm_daily, how='inner')\n",
    "\n",
    "if len(compare) > 0:\n",
    "    ct = pd.crosstab(compare['Regime_label'], compare['regime'])\n",
    "    ct_pct = ct.div(ct.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    sns.heatmap(ct_pct, annot=True, fmt='.0f', cmap='YlOrRd', ax=ax)\n",
    "    ax.set_title('GMM Regime label vs K-Means Cluster (% of GMM regime days)')\n",
    "    ax.set_xlabel('K-Means Regime')\n",
    "    ax.set_ylabel('GMM Regime Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print('No overlapping dates for comparison (GMM data may not cover the full range).')"
   ]
  }
 ]
}
